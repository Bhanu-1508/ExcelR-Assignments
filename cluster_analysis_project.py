# -*- coding: utf-8 -*-
"""Cluster analysis Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tYph6XVs6rBR6Eg_O5H29V18HNKepHd0
"""

import pandas as pd

# Load the dataset
file_path = 'World_development_mesurement.xlsx'
data = pd.read_excel(file_path)

# Display the first few rows of the dataset
data.head()

# Check for missing values
missing_values = data.isnull().sum()

# Get basic statistics
basic_stats = data.describe()

# Display the information
missing_values, basic_stats

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

# Handling missing values
imputer = SimpleImputer(strategy='mean')
data_imputed = pd.DataFrame(imputer.fit_transform(data.select_dtypes(include=['float64', 'int64'])), columns=data.select_dtypes(include=['float64', 'int64']).columns)

# Normalizing the data
scaler = StandardScaler()
data_normalized = pd.DataFrame(scaler.fit_transform(data_imputed), columns=data_imputed.columns)

# If there are non-numeric columns, let's add them back to the normalized data
non_numeric_data = data.select_dtypes(exclude=['float64', 'int64'])
data_final = pd.concat([data_normalized, non_numeric_data.reset_index(drop=True)], axis=1)

data_final.head()

from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN
import matplotlib.pyplot as plt
import seaborn as sns

# Choosing the number of clusters (Elbow Method)
sse = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(data_normalized)
    sse.append(kmeans.inertia_)

# Plotting the elbow curve
plt.figure(figsize=(10, 6))
plt.plot(range(1, 11), sse, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('SSE')
plt.title('Elbow Method for Optimal k')
plt.show()

# Applying KMeans with the optimal number of clusters
optimal_k = 3  # For example, if 3 is the optimal number of clusters from the elbow plot
kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
data_final['Cluster'] = kmeans.fit_predict(data_normalized)
# Visualizing the clusters
plt.figure(figsize=(10, 6))
# Removed the leading space in the column name for the y-axis
sns.scatterplot(data=data_final, x='GDP', y='Life Expectancy Female', hue='Cluster', palette='viridis')
plt.title('Clusters of Countries')
plt.xlabel('GDP')
plt.ylabel('Life Expectancy (Female)')
plt.legend()
plt.show()

# Agglomerative Clustering
agg = AgglomerativeClustering(n_clusters=3)
data_final['Agglomerative_Cluster'] = agg.fit_predict(data_normalized)
plt.subplot(1, 3, 2)
sns.scatterplot(data=data_final, x='GDP', y='Life Expectancy Female', hue='Agglomerative_Cluster', palette='viridis')
plt.title('Agglomerative Clusters')
plt.xlabel('GDP')
plt.ylabel('Life Expectancy (Female)')

# DBSCAN
dbscan = DBSCAN(eps=0.5, min_samples=5)
data_final['DBSCAN_Cluster'] = dbscan.fit_predict(data_normalized)
plt.subplot(1, 3, 3)
sns.scatterplot(data=data_final, x='GDP', y='Life Expectancy Female', hue='DBSCAN_Cluster', palette='viridis')
plt.title('DBSCAN Clusters')
plt.xlabel('GDP')
plt.ylabel('Life Expectancy (Female)')
plt.tight_layout()
plt.show()

"""# Comperative analysis

"""

from sklearn.metrics import silhouette_score

# Compute silhouette scores for K-Means and Agglomerative Clustering
kmeans_silhouette = silhouette_score(data_normalized, data_final['Cluster'])
agg_silhouette = silhouette_score(data_normalized, data_final['Agglomerative_Cluster'])

print(f'K-Means Silhouette Score: {kmeans_silhouette}')
print(f'Agglomerative Clustering Silhouette Score: {agg_silhouette}')

import streamlit as st
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
@st.cache
def load_data():
    file_path = 'World_development_mesurement.xlsx'
    data = pd.read_excel(file_path)
    return data

# Perform clustering
def perform_clustering(data, method):
    data.columns = data.columns.str.strip()
    imputer = SimpleImputer(strategy='mean')
    data_imputed = pd.DataFrame(imputer.fit_transform(data.select_dtypes(include=['float64', 'int64'])), columns=data.select_dtypes(include=['float64', 'int64']).columns)
    scaler = StandardScaler()
    data_normalized = pd.DataFrame(scaler.fit_transform(data_imputed), columns=data_imputed.columns)

    if method == 'K-Means':
        model = KMeans(n_clusters=3, random_state=42, n_init=10)
    elif method == 'Agglomerative':
        model = AgglomerativeClustering(n_clusters=3)
    else:
        model = DBSCAN(eps=0.5, min_samples=5)

    data['Cluster'] = model.fit_predict(data_normalized)
    return data

# Streamlit application
st.title('Clustering Application for Global Development Metrics')

data = load_data()
method = st.selectbox('Select Clustering Method', ('K-Means', 'Agglomerative', 'DBSCAN'))
data_clustered = perform_clustering(data, method)

st.write(f'Clustered Data using {method}')
st.write(data_clustered.head())

# Visualize the clusters
fig, ax = plt.subplots()
sns.scatterplot(data=data_clustered, x='GDP', y='Life Expectancy Female', hue='Cluster', palette='viridis', ax=ax)
plt.title(f'{method} Clusters')
plt.xlabel('GDP')
plt.ylabel('Life Expectancy (Female)')
st.pyplot(fig)